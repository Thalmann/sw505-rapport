\input{./indhold/notation}

\section{Sandsynlighedsteori}
Som beskrevet i \cref{sensorer} kan robottens viden omkring verdenen den bevæger sig i ikke være komplet pga. måleusikkerheder.\thilemann{Bør vi nævne at den dog kender sin position via kameraet?}
På trods af dette er den nødt til at kunne reagere på den netop tilgængelige viden, hvorfor det er nødvendigt med metoder der gør det muligt at resonerer sig frem til et 'bedste' valg.
Dette afsnit introducerer den nødvendige sandsynlighedsteori for at kunne beskrive hvad der gør sig gældende i en given verden, baseret på robottens observationer af netop denne.

Sandsynlighedsteori omhandler hvordan viden har indflydelse på vores opfattelse af en given verden (\textit{belief}).
I en proposition $\alpha$ måles vores opfattelse som en værdi mellem 0 og 1, hvor 0 betegner $\alpha$ som værende definitivt falsk, og 1 definitivt sand.
Har $\alpha$ en værdi mellem 0 og 1 betegnes den således ikke til at være sand 'til en vis grad', men blot at vi ved at den er hverken sand eller falsk.
Indholdet i dette afsnit er baseret på afsnit fra \cite{ArtificialIntelligence}.

\subsection{Semantik for sandsynlighed}
I dette afsnit angives den semantik der i resten af rapporten vil blive benyttet til at beskrive sandsynligheder samt de områder indenfor sandsynlighedsteori der er relevante ift. at arbejde med en ukendt posterior givet en prior i sandsynlighedsbaseret robotteknik.

Et sandsynlighedsmål $\mu$ er en funktion fra en mængde verdener til mængden af positive reelle tal. 
Hvis det gælder at $\Omega_1 \cap \Omega_2 = \{{}\}$, hvor $\Omega_1$ og $\Omega_2$ er mængder af verdener, har vi at:

\begin{enumerate}
\item $\mu(\Omega_1 \cup \Omega_2) = \mu(\Omega_1) + \mu(\Omega_2)$
\item Hvis $\Omega$ er mængden af alle verdener vil $\mu(\Omega) = 1$ 
\end{enumerate}

Sandsynlighedsmålet kan udviddes til at dække sandsynligheden for enkelte verdener således at:
$$\mu(\omega) = \mu(\{\omega\})$$

Er propositioner hvor $P(\alpha)$ er målet af mængden af verdener og $\alpha$ er sand.
Det vil sige at:
$$P(\alpha) = \mu(\{\omega \mid \omega \models \alpha \})$$
Her betyder notationen $\omega \models \alpha$ at propositionen $\alpha$ er sand i verdenen $\omega$.

Notationen kan yderligere udvides til at dække \emph{stokastiske variabler}.
En sandsynlighedsfordeling $P(X)$ over variablen $ X $, er en funktion fra
domænet for $ X $ til mængden af positive reelle tal.
Således at givet $x \in dom(X)$, vil $P(x)$ være sandsynligheden for at $X = x$.

Denne notation kan også benyttes til at beskrive sandsynligheder af flere variabler.
F.eks. er $P(X,Y)$ en sandsynlighedsfordeling over variablerne $ X $ og $ Y $, således at $P(X = x \wedge Y = y)$ (hvor $x \in dom(X)$ og $y \in dom(Y)$), har værdien $P(X = x \wedge Y = y)$.
$X = x \wedge Y = y$ er en proposition og $ P $ er funktionen over propositioner. 


\subsection{Betinget sandsynlighed}
Vi er dog ikke kun interesseret i sandsynlighederne for hvad der er sket; vi ønsker også at være i stand til at sige noget om hvad der \textit{vil} ske, altså hvordan vi kan opdatere vores opfattelse af verden givet robotten har gjort nye observationer.

Dette kaldes for den betingede sandsynlighed, og skrives $P(h \mid e)$, hvor $ e $ betegner en agents observationer om en verden, altså dens \textit{evidens}.
Det udtrykker troen på en given proposition $ h $ givet $ e $, som er vores prior.


\subsubsection{Definition af betinget sandsynlighed}
Lad $\mu_e$ være et sandsynlighedsmål.
Hvis $\Omega$ er mængden af alle verdener, så kan $\mu_e(\Omega)$ siges at være lig 0.
Derfor gælder det at $1 = \mu_e(\Omega) = \mu_e(\{ w : w \models e \}) + \mu_e(\{ w : w \not\models e \}) = c \times \mu(\{ w : w \models e\}) + 0 = c \times P(e)$, hvor $c = 1/P(e)$.
\thilemann{forklaring af ovenstående og nedenstående formler}

\begin{align*}
P(h \mid e) \quad = \quad & \mu_e(\{\omega \mid \omega \models h \})\\
\quad = \quad & \mu_e(\{\omega \mid \omega \models h \wedge e \}) + \mu_e(\{\omega \mid \omega \models h \wedge \neg e \})\\
\quad = \quad & \frac{\mu(\{\omega \mid \omega \models h \wedge e \})}{P(e)} + 0\\
\quad = \quad & \frac{P(h \wedge e)}{P(e)}, \quad \textrm{hvor $P(e) > 0$.}
\end{align*}


\subsubsection{Kædereglen}
Kædereglen benyttes til at beregne ethvert medlem af en fællesdistribution fra en mængde af stokastiske variabler vha. betingede sandsynligheder. 
Givet en distribution af propositioner, kan kædereglen således benyttes til at finde skæringspunktet mellem to variabler, $\alpha_1$ og $\alpha_2$, hvor man ønsker at finde den ene givet den anden.\thilemann{review please...}

\begin{align*}
P(\alpha_1 \wedge \alpha_2 \wedge \ldots \wedge \alpha_n) \quad = \quad & P(\alpha_1) \quad \times\\
& P(\alpha_1 \mid \alpha_1) \quad \times\\
& P(\alpha_3 \mid \alpha_1 \wedge \alpha_2) \quad \times\\
& \vdots \\
& P(\alpha_n \mid \alpha_1 \wedge \dots \wedge \alpha_{n-1}) \quad \times\\
= \quad &\prod_{i = 1}^{n} P(\alpha_i \mid \alpha_1 \wedge \dots \wedge \alpha_{i-1}),
\end{align*}
\begin{quotation}
\textit{hvor højre-siden antages til at være nul, hvis ethvert medlem af produkterne er nul.}
\end{quotation}

Kædereglen er især nyttig ved beregninger af bayesianske netværk og ved brug af \textit{Bayes Regel} (\cref{sandsynlighed:bayes_regel}).


\subsubsection{Bayes Regel}\label{sandsynlighed:bayes_regel}
Bayes Regel spiller en stor rolle i sandsynlighedsteori, da den siger hvordan vi kan beregne en ny posterior ud fra en kendt prior sandsynlighedsdistribution.
Den er således defineret som:

$$P(h \mid e) = \frac{\mathit{sandsynlighed} \times \mathit{prior})}{\mathit{normaliseringsfunktion}} = \frac{P(e \mid h) \times P(h)}{P(e)},$$

\begin{quotation}
\textit{hvor $P(h \mid e)$ er posterior sandsynlighed, $P(e \mid h)$ er sandsynligheden og $P(h)$ er prior.}
\end{quotation}

Leder vi Bayes Regel hen på robotteknik givet to variabler $X$ og $Z$, hvor $X$ er en celle f.eks. et occupancy grid (\cref{mapping:occupancy_grid}) og $Z$ er sensormålinger.
Så kan den næste posterior (for en celle $X_i$) givet sensormålinger, findes ved:

$$P(X_i \mid Z) = \frac{P(Z \mid X_i) \times P(X_i)}{P(Z)}$$

Tælleren i Bayes Regel kan betegnes som en ikke-normaliseret sandsynlighedsdistribution, hvor nævneren er en normaliseringsfunktion, givet ved:

$$P(Z) = \sum_{i}^{} P(Z \mid X_i) \times P(X_i),$$

hvilket svarer til kædereglen benyttet på hver enkelt celle i grid'et.


\subsection{Binære Bayes filtre med statisk tilstand}\label{bayes_binaerfiltre}
I tilfælde hvor tilstanden er statisk, altså hvor verden ikke ændrer sig over tid, kan der anvendes binære Bayes filtre.
Her kan en \textit{belief} på en given tilstand $x$ beskrives som:

$$bel_t(x) = p(x \mid z_{1:t},u_{1:t}) = p(x \mid z_{1:t})$$

Hvor tilstanden $x$ er binær, dvs. enten sand ($x$) eller falsk ($\lnot x$).
Derved har vi at $bel_t(\lnot x) = 1 - bel_t(x)$.
Bemærk desuden at $x$ altid er den samme, og der ikke findes en $x$ for ethvert tidspunkt $t$, da verden er statisk.

\subsubsection{Log Odds}
Er en metode der kan benyttes for at undgå at komponenterne i Bayes Regel enten bliver definitivt sande eller falske.
I så fald vil det ikke være muligt at beregne ny posterior, da de enkelte komponenter ikke vil have nogen effekt.

Der kan derfor indføres en funktion, \textit{log odds ratio}, som konverterer sandsynlighedsværdierne fra $[0;1]$ til $[-\infty;\infty]$.
Oddset for tilstand $x$ er defineret som forholdet mellem sandsynlighederne for $x$ og $\lnot x$:

$$\frac{p(x)}{p(\lnot x)} = \frac{p(x)}{1 - p(x)}$$
\\
Log oddset er logaritmen til forholdet mellem de to sandsynligheder:

$$l(x) := \log \frac{p(x)}{1 - p(x)}$$

\subsubsection{Opdaterings algoritme}
\thilemann{Her beskrives celler med anden notation end den angivet i mapping. Bør det ikke være den samme?}
Opdaterings-algoritmen tager \textit{log odds} for en \textit{posterior belief} $l_{t-1}$ for en celle, samt en ny sensor-måling $z_t$, hvor ud fra der returneres en \textit{log odds} for en ny \textit{belief} $l_t$ for cellen.
\thilemann{Der står 'opdaterings-algoritmen' (bestemt ental), men synes ikke det står specielt klart hvad den opdaterer.}
Algoritmen, skrevet i pseudo-kode, kan ses i \cref{alg:binaerbayesfilter}.

\begin{algorithm}[h]
\textbf{BinaryBayesFilter($l_{t-1}, z_t$)} \\
\Indp $l_t = l_{t-1} + \log \frac{p(x \mid z_t)}{1-p(x \mid z_t)} - \log \frac{p(x)}{1-p(x)}$ \\
\Return{$l_t$}
\caption{Binært Bayes filter algoritme}
\label{alg:binaerbayesfilter}
\end{algorithm}


For at få vores \textit{belief} $bel_t(x)$ tilbage ud fra en \textit{log odds} $l_t$, benyttes følgende ligning:

$$bel_t(x) = 1 - \frac{1}{1 + exp\{l_t\}}$$
